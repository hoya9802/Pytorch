import torch
from torch import nn, optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
from functions import *


# Window version
# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# M1 MAC version
DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')

print(DEVICE)


BATCH_SIZE = 32
LR = 1e-3
EPOCH = 5
criterion = nn.CrossEntropyLoss()
new_model_train = True
model_type = 'CNN'
dataset = "CIFAR10"
save_model_path = f'/Users/euntaeklee/Git_Project/Pytorch/result/{model_type}_{dataset}.pt'


transform = transforms.ToTensor()
train_DS = datasets.CIFAR10(root='/Users/euntaeklee/Git_Project/data', train=True, download=True, transform=transform)
test_DS = datasets.CIFAR10(root='/Users/euntaeklee/Git_Project/data', train=False, download=True, transform=transform)
train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)
test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)


print(train_DS)
print(test_DS)
print(len(train_DS))
print(len(test_DS))


print(test_DS.classes)
print(test_DS.class_to_idx)
x_batch, y_batch = next(iter(test_DL))
print(x_batch.shape)
plt.imshow(x_batch[0].permute(1,2,0))
print(test_DS.classes[y_batch[0]])


# 1. change to tensor
# 2. change to "numxchannelxrowxcolumn"
# 3, change into 0 to 1 (int -> float)
print(type(train_DS.data))
print(train_DS.data.shape)
print(train_DS.data.dtype)
print(train_DS.data[0][0][0][0])
x_batch, y_batch = next(iter(train_DL)) # select one by using next(iter(train_DS))
print(type(x_batch))
print(x_batch.shape)
print(x_batch.dtype)
print(x_batch[0][0][0][0])


class CNN(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Sequential(
            nn.Conv2d(3,8,3,padding=1),
            nn.BatchNorm2d(8),
            nn.ReLU())
        self.conv2 = nn.Sequential(
            nn.Conv2d(8,16,3,padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU())
        self.conv3 = nn.Sequential(
            nn.Conv2d(16,32,3,padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU())
        self.maxp = nn.MaxPool2d(2)
        self.fc = nn.Linear(32*64,10)

    def forward(self, x):
        x = self.conv1(x) 
        x = self.maxp(x)
        x = self.conv2(x)
        x = self.maxp(x)
        x = self.conv3(x)
        x = torch.flatten(x, start_dim=1)
        x = self.fc(x)
        return x


exec(f'model = {model_type}()')
print(model)


if new_model_train:
    model = model.to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    loss_history = Train(model, train_DL, criterion, optimizer, EPOCH)

    torch.save(model, save_model_path)

    plt.plot(range(1, EPOCH+1), loss_history)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Train Loss')
    plt.grid()


load_model = torch.load(save_model_path)


Test(load_model, test_DL)
print(count_params(load_model))


Test_plot(load_model, test_DL)



