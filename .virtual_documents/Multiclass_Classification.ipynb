import torch
from torchvision import datasets, transforms
import matplotlib.pyplot as plt





# Window version
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# M1 MAC version
DEVICE = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')

print(DEVICE)


# MNIST Data Load
transform = transforms.ToTensor()
train_DS = datasets.MNIST(root="path", train=True, download=True, transform=transform)
test_DS = datasets.MNIST(root="path", train=False, download=True, transform=transform)


print(train_DS)
print(test_DS)
print(len(train_DS))
print(len(test_DS))


train_DS.classes


train_DS.class_to_idx


train_DS.data.shape


train_DS.data[0]


plt.imshow(train_DS.data[0], cmap='gray')
plt.colorbar()


print(train_DS.targets[-1])
print(train_DS.targets.shape)





BATCH_SIZE = 32
train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)
test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)


print(len(train_DL.dataset))


x_batch, y_batch = next(iter(train_DL)) # One data group per batch
print(type(train_DS.data))
print(type(x_batch.data))
print(x_batch.shape)
print(y_batch.shape)
plt.imshow(x_batch[0].squeeze(), cmap='gray')  # if you want to get image, you should use .squeeze() function
plt.colorbar()
print(y_batch[0])

print(train_DL.dataset.data.dtype)
print(x_batch.dtype)
# Role of ToTenser
# 1. change to tensor form
# 2. change to "numberxchannelxrowxcolumn" form
# 3. switch to 0 to 1 (int -> float)





from torch import nn

class MLP(nn.Module):
    def __init__(self):
        super().__init__()

        self.linear = nn.Sequential(
            nn.Linear(784, 100),
            nn.ReLU(),
            nn.Linear(100, 10))

    def forward(self, x):
        x = torch.flatten(x, start_dim=1)
        x = self.linear(x)

        return x


# flatten
x_batch, _ = next(iter(train_DL))
print(x_batch.shape)
flat_images = torch.flatten(x_batch)
print(x_batch.shape[0]*x_batch.shape[1]*x_batch.shape[2]*x_batch.shape[-1])
print(flat_images.shape)
flat_images2 = torch.flatten(x_batch, start_dim=1)
print(flat_images2.shape)


model = MLP()
print(model)
print(model(x_batch).shape)





from torch import nn
from torch import optim

lr = 1e-3
epoch = 5
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=lr)

def Train(model, train_DL, criterion, optimizer):
    loss_history = []
    NoT = len(train_DL.dataset)
    
    model.train()
    for it in range(epoch):
        rloss = 0
        for x_batch, y_batch in train_DL:
            x_batch = x_batch.to(DEVICE)
            y_batch = y_batch.to(DEVICE)
            # inference
            y_hat = model(x_batch)
            # loss
            loss = criterion(y_hat, y_batch)
            # update
            optimizer.zero_grad() # prevent stack of gradient
            loss.backward() # BPP
            optimizer.step() # Weight update
            # loss accumulation
            loss_b = loss.item() * x_batch.shape[0]
            rloss += loss_b
        # print loss
        loss_e = rloss/NoT
        loss_history += [loss.item()]
        print(f'Epoch: {it+1}, train loss: {round(loss_e, 3)}')
        print("-"*30)
        
    return loss_history





# various way to calculate cross entropy
import torch.nn.functional as F

y_hat = torch.randn(3,5) # Assume there are three types of data
print(y_hat) # The sum of rows before passing through the softmax layer is not 1
y_batch = torch.randint(5, (3,))
print(y_batch)

# method 1
loss = F.cross_entropy(y_hat, y_batch) # It already has a built-in softmax.
print(loss)

# method 2
criterion = nn.CrossEntropyLoss() # It already has a built-in softmax.
print(criterion(y_hat, y_batch))

# method 3
y_hat_soft = F.softmax(y_hat, dim=1)
print(y_hat_soft)
loss = 0
for i, val in enumerate(y_hat_soft):
    print(i, val)
    loss += -torch.log(val[y_batch[i]])
print(loss/3)


model = MLP().to(DEVICE) # you should upload x_batch, y_batch, model into GPU device!
loss_history = Train(model, train_DL, criterion, optimizer)

plt.plot(range(1, epoch+1), loss_history)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Train Loss')
plt.grid()





torch.save(model.state_)
